{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c98f6b49",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f7efac",
   "metadata": {},
   "source": [
    "The notebook gives an example of how one can deal with tabular data using tensorflow. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95ed80e",
   "metadata": {},
   "source": [
    "> This will be a very quick example. For more details, consult the TensorFlow documentation. The material below is following the tutorial https://www.tensorflow.org/tutorials/structured_data/preprocessing_layers quite closely, using many of the functions shown there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a0ba3e",
   "metadata": {},
   "source": [
    "**Main takeaways and motivation:**\n",
    "\n",
    "* Last time we had a look at an image classification example in TensorFlow. This notebook continues our explorations by showcasing a different kind of problem and data set\n",
    "* Get to know some important TensorFlow concepts and players, e.g., `tf.data` and preprocessing layers.\n",
    "* See that it is possible to use non neural net-based models in TensorFlow, compatible with the other components of TensorFlow. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7a4aca",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4b04d0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np, pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ef8a41",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e45a0f5",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ea9b43",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We'll use a version of the heart disease data set from UCI ML repository: https://archive.ics.uci.edu/ml/datasets/heart+Disease"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6cef1e",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Load data as a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f970552",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# We use a version of the data prepared by TensorFlow\n",
    "url = 'https://storage.googleapis.com/download.tensorflow.org/data/heart.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d651f90",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b743d7b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f953bc54",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68219092",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bfba91",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8737f924",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1522df",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce42e79e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6b5419",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Create a data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3609574b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#tf.data.Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08487247",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "`Dataset` usage follows a common pattern:\n",
    "\n",
    "1. Create a source dataset from your input data.\n",
    "2. Apply dataset transformations to preprocess the data.\n",
    "3. Iterate over the dataset and process the elements.\n",
    "\n",
    "Iteration happens in a streaming fashion, so the full dataset does not need to\n",
    "fit into memory.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e297790",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We create a train and a test dataset from the corresponding data frames. We want to shuffle the training data while keeping the test set as it is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0d4ba1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# From \n",
    "# https://www.tensorflow.org/tutorials/structured_data/preprocessing_layers#create_an_input_pipeline_using_tfdata\n",
    "\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=8):\n",
    "    df = dataframe.copy()\n",
    "    labels = df.pop('target')\n",
    "    df_dict = {key: value[:,tf.newaxis] for key, value in dataframe.items()}\n",
    "    \n",
    "    # Create a tf Dataset\n",
    "    ds = tf.data.Dataset.from_tensor_slices((df_dict, labels))\n",
    "    \n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "        \n",
    "    # Create batches of data\n",
    "    ds = ds.batch(batch_size)\n",
    "    \n",
    "    # Prefetch data (for efficiency: data can be prepared while \n",
    "    # current data is processing)\n",
    "    ds = ds.prefetch(batch_size)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4693ea",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "train_ds = df_to_dataset(train, shuffle=True, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758c1728",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95ba4da",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here's a batch of data from the train dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbe4b1b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "[(train_features, label_batch)] = train_ds.take(1)\n",
    "print('Features:', list(train_features.keys()))\n",
    "print('A batch of ages:', train_features['age'])\n",
    "print('A batch of targets:', label_batch )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00d3fd4",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad63e331",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We'll use preprocessing layers from Keras (https://www.tensorflow.org/guide/keras/preprocessing_layers) rather than preprocess separately using for example Pandas or scikit-learn.\n",
    "\n",
    "> _\"With Keras preprocessing layers, you can build and export models that are truly end-to-end: models that accept raw images or raw structured data as input; models that handle feature normalization or feature value indexing on their own.\"_ [source](https://www.tensorflow.org/guide/keras/preprocessing_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6ce417",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9a78de",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949b8f43",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We see that we have numerical, ordinal and categorical features. We want to normalize the numerical and ordinal features, and one-hot encode the categorical features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987bb47c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "numerical = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'restecg']\n",
    "categorical = ['cp', 'fbs', 'exang', 'slope', 'ca', 'thal']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaf7441",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Set up normalization layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8316779",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "?layers.Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504d0541",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_normalization_layer(name, dataset):\n",
    "    # Create a Normalization layer for the feature.\n",
    "    normalizer = layers.Normalization(axis=None)\n",
    "\n",
    "    # Prepare a Dataset that only yields the feature.\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "    # Learn the statistics of the data.\n",
    "    normalizer.adapt(feature_ds)\n",
    "\n",
    "    return normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d01d486",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Note how the above code resembles doing normalization in scikit-learn: \n",
    "\n",
    "```\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler()\n",
    "std.fit(X_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f29522",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Test the function:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f6517c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "chol = train_features['chol']\n",
    "chol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc3fa91",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "norm_layer = get_normalization_layer('chol', train_ds)\n",
    "norm_layer(chol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12530c08",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Set up categorial encoding layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38cea5c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We want to one-hot encode the categorical variables. We can use the various encoding layers from TensorFlow/Keras to achieve this.\n",
    "\n",
    "We need to convert all the categorical features represented as numbers, and also the string feature `thal`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097829b2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#?layers.StringLookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6672084e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#?layers.IntegerLookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6655fdf8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#?layers.CategoryEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2fc741",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
    "    # Create a layer that turns strings into integer indices.\n",
    "    if dtype == 'string':\n",
    "        index = layers.StringLookup(max_tokens=max_tokens)\n",
    "    # Otherwise, create a layer that turns integer values into integer indices.\n",
    "    else:\n",
    "        index = layers.IntegerLookup(max_tokens=max_tokens)\n",
    "\n",
    "    # Prepare a `tf.data.Dataset` that only yields the feature.\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "    # Learn the set of possible values and assign them a fixed integer index.\n",
    "    index.adapt(feature_ds)\n",
    "\n",
    "    # Encode the integer indices.\n",
    "    encoder = layers.CategoryEncoding(num_tokens=index.vocabulary_size())\n",
    "\n",
    "    # Apply multi-hot encoding to the indices. The lambda function captures the\n",
    "    # layer, so you can use them, or include them in the Keras Functional model later.\n",
    "    return lambda feature: encoder(index(feature))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df41801a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e66237",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_type_col = train_features['thal']\n",
    "test_type_layer = get_category_encoding_layer(name='thal',\n",
    "                                              dataset=train_ds,\n",
    "                                              dtype='string')\n",
    "test_type_layer(test_type_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a75ae8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_age_col = train_features['sex']\n",
    "test_age_layer = get_category_encoding_layer(name='sex',\n",
    "                                             dataset=train_ds,\n",
    "                                             dtype='int64',\n",
    "                                             max_tokens=2)\n",
    "test_age_layer(test_age_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf3b5e0",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Preprocess all the features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f40066",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We normalize all the numerical features and one-hot encode the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b8dfe1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_inputs = []\n",
    "encoded_features = []\n",
    "\n",
    "# Numerical features.\n",
    "for header in numerical:\n",
    "    numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
    "    normalization_layer = get_normalization_layer(header, train_ds)\n",
    "    encoded_numeric_col = normalization_layer(numeric_col)\n",
    "    all_inputs.append(numeric_col)\n",
    "    encoded_features.append(encoded_numeric_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32a3854",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for header in categorical[:-1]: # All except `thal`, which is a string feature\n",
    "    categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='int64')\n",
    "    encoding_layer = get_category_encoding_layer(name=header,\n",
    "                                               dataset=train_ds,\n",
    "                                               dtype='int64',\n",
    "                                               max_tokens=5)\n",
    "    encoded_categorical_col = encoding_layer(categorical_col)\n",
    "    all_inputs.append(categorical_col)\n",
    "    encoded_features.append(encoded_categorical_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87b6530",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Encode `thal` separately (a string feature):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa8b0ba",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "categorical_col = tf.keras.Input(shape=(1,), name='thal', dtype='string')\n",
    "encoding_layer = get_category_encoding_layer(name='thal',\n",
    "                                           dataset=train_ds,\n",
    "                                           dtype='string',\n",
    "                                           max_tokens=5)\n",
    "encoded_categorical_col = encoding_layer(categorical_col)\n",
    "all_inputs.append(categorical_col)\n",
    "encoded_features.append(encoded_categorical_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5c2393",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we have 12 encoded features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad619ac",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "encoded_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0483c382",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Train a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c199c90c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We'll make a simple one-layer neural network on top of the preprocessing layers defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794ed937",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_features = tf.keras.layers.concatenate(encoded_features)\n",
    "x = tf.keras.layers.Dense(32, activation=\"relu\")(all_features)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "output = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "model = tf.keras.Model(all_inputs, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763ffd38",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2603c2c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here's our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafc844f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e123d7ad",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.fit(train_ds, epochs=10, validation_data=test_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6180b1a9",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18e7497",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d686973",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0743273",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we can export the model (which includes all the preprocessing steps) to the [SaveModel format](https://www.tensorflow.org/guide/saved_model). This can then later be imported elsewhere, f.ex. for model deployment using [TensorFlow Serving](https://www.tensorflow.org/tfx/guide/serving) or similar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f229a4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#?tf.keras.models.save_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2196228b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> We'll look more at this when we talk about TensorFlow Extended later in the module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572cb3c1",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Extra: Train a tree-based model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf78fc0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We could alternatively use the TensorFlow Decision Forests library, which can use a collection of state-of-the-art algorithm,s for training, serving and interpreting decision forest models (random forest, gradient boosted trees, etc):\n",
    "\n",
    "https://github.com/google/yggdrasil-decision-forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85eb9ec",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import tensorflow_decision_forests as tfdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e336432c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_ds_trees = tfdf.keras.pd_dataframe_to_tf_dataset(train, label=\"target\")\n",
    "test_ds_trees = tfdf.keras.pd_dataframe_to_tf_dataset(test, label=\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343a4570",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = tfdf.keras.RandomForestModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2197c4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7aa36d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.fit(train_ds_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ce0961",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad563c97",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_ds_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706e50ae",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dc41ff",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "IPython.display.HTML(tfdf.model_plotter.plot_model(model, tree_idx=0, max_depth=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962c1a59",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588c7d38",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.make_inspector().variable_importances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bc16cd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logs = model.make_inspector().training_logs()\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot([log.num_trees for log in logs], [log.evaluation.accuracy for log in logs])\n",
    "plt.xlabel(\"Number of trees\")\n",
    "plt.ylabel(\"Accuracy (out-of-bag)\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot([log.num_trees for log in logs], [log.evaluation.loss for log in logs])\n",
    "plt.xlabel(\"Number of trees\")\n",
    "plt.ylabel(\"Logloss (out-of-bag)\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63afca91",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796c471e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This model can also be exported to a SavedModel, and then served using TensorFlow Serving or similar.\n",
    "\n",
    "https://www.tensorflow.org/decision_forests/tensorflow_serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7755dfc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#model.save(\"rf_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
