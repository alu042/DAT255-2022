{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92a665fa",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d290fc",
   "metadata": {},
   "source": [
    "The notebook expands upon the image classification example in notebook `1.1-flowers-in-tensorflow.ipynb`, illustrating some additional ideas and concepts from TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a9bda4",
   "metadata": {},
   "source": [
    "**Main takeaways and motivation:**\n",
    "\n",
    "* Last time we had a look at an image classification example in TensorFlow. There, we used high-level functionality from Keras to read images from disk. This time we'll use the more efficient TFRecords format to store the images, and show how to work with TFRecords in TensorFlow.\n",
    "* .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f540d870",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303fb14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "import pickle, PIL, os\n",
    "from pathlib import Path\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\";\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfec0d3a",
   "metadata": {},
   "source": [
    "# Load the flowers data and store as TFRecords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fc29fe",
   "metadata": {},
   "source": [
    "This is the data set we downloaded in the notebook `0.1-download_flowers_data.ipynb`, and studied in the two notebooks `1.0` (fastai) and `2.0` (TensorFlow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba695d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('path.pkl', 'rb') as f:\n",
    "    path = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9909f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(path.iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bdc47d",
   "metadata": {},
   "source": [
    "**Plot some random images:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d023ca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a705d7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kind = 'sunflowers'\n",
    "nb = 9\n",
    "images = random.choices(list((path/kind).iterdir()), k=nb)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    img = PIL.Image.open(images[i])\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98aaa2b5",
   "metadata": {},
   "source": [
    "## Split images into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba62135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = list(path.glob(\"*/*.jpg\"))\n",
    "nb_images = len(all_images)\n",
    "nb_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f55c04",
   "metadata": {},
   "source": [
    "We shuffle the images to make sure we can get all classes in the test set by slicing the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4b1073",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaec04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b582307",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = all_images[:int((1-test_size)*nb_images)]\n",
    "\n",
    "test_images = all_images[int((1-test_size)*nb_images):]\n",
    "\n",
    "print(f\"nb train images: {len(train_images)}\\n nb test images: {len(test_images)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143db8c7",
   "metadata": {},
   "source": [
    "## Load and store as TFRecord"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139f5449",
   "metadata": {},
   "source": [
    "> TFRecord is a data format for storing sequences of binary records. Performance-wise, binary formats allow for fast reading and writing. TensorFlow has several optimization that are based on TFRecord, allowing for seamless integration with everything from preprocessing layers to distributed data sets. \n",
    "\n",
    "https://www.tensorflow.org/tutorials/load_data/tfrecord"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48183e79",
   "metadata": {},
   "source": [
    "We're going to store the images as binary records, using TFRecord. For this, we need to specify the structure of the data, including the labels we want to assign to each image. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5594b3b",
   "metadata": {},
   "source": [
    "### Get labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee180c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(path.iterdir()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01867cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {0: 'daisy',\n",
    "               1: 'dandelion',\n",
    "               2: 'roses',\n",
    "               3: 'sunflowers',\n",
    "               4: 'tulips'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae39e47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict_reversed = {v: k for k,v in labels_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dc1326",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict_reversed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe694f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(img_path):\n",
    "    label = img_path.parent.stem\n",
    "    return labels_dict_reversed[label]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de96bf58",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea555b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_path = train_images[10]\n",
    "test_img = PIL.Image.open(test_img_path)\n",
    "test_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c172f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_label(test_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552d499a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict[get_label(test_img_path)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5251d5c9",
   "metadata": {},
   "source": [
    "### Save the raw image data byte strings in a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70b27a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_tensor = tf.io.read_file(str(test_img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9c793b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_img_tensor.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260c44ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_tensor.numpy()[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59febfe",
   "metadata": {},
   "source": [
    "### Construct `tf.train.Example`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208737c2",
   "metadata": {},
   "source": [
    "To specify the structure of the data stored as byte strings, we can use `tf.train.Example`, a standard [protocol buffer](https://developers.google.com/protocol-buffers/?hl=en) for serializing data (created by Google): https://www.tensorflow.org/api_docs/python/tf/train/Example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452994e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#?tf.train.Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ebf9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#?tf.train.Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff1880a",
   "metadata": {},
   "source": [
    "Helper functions to turn values into lists that are then turned into a list of values to use in `tf.train.Example`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679d6855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809dde2a",
   "metadata": {},
   "source": [
    "**Test:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f9a51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_example = tf.train.Example(features=tf.train.Features(\n",
    "    feature = {'image_raw': _bytes_feature(test_img_tensor.numpy()), \n",
    "               'label': _int64_feature(get_label(test_img_path))}\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e7caa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86cbe0a",
   "metadata": {},
   "source": [
    "### Write all images to tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86deb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecord_train_fn = str(path/'flowers_dataset_train.tfrecord')\n",
    "tfrecord_test_fn = str(path/'flowers_dataset_test.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18204ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_tfrecord(images, tfrecord_fn):\n",
    "    if not os.path.isfile(tfrecord_fn):\n",
    "        with tf.io.TFRecordWriter(tfrecord_fn) as writer:\n",
    "            for img_path in images:\n",
    "                try:\n",
    "                    raw_file = tf.io.read_file(str(img_path))\n",
    "                except:\n",
    "                    print(f\"File {img_path} could not be found (or read)\")\n",
    "                    continue\n",
    "\n",
    "                example = tf.train.Example(features=tf.train.Features(\n",
    "                            feature = {'image_raw': _bytes_feature(raw_file.numpy()), \n",
    "                                       'label': _int64_feature(get_label(img_path))}\n",
    "        ))\n",
    "                writer.write(example.SerializeToString())\n",
    "                \n",
    "            print(f\"TFRecord written to {tfrecord_fn}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"TFRecords already written to disk: {tfrecord_fn}\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed256150",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tfrecord(train_images, tfrecord_train_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b96a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tfrecord(test_images, tfrecord_test_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc479e1c",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd24b8d",
   "metadata": {},
   "source": [
    "We can now construct data sets and dataloaders that gets data from the stored TFRecords. For this, we use the `tf.data` API: https://www.tensorflow.org/guide/data_performance. We'll partly follow the example from https://keras.io/examples/keras_recipes/tfrecord/. Have a look at this example for some additional details and links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2494df28",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "IMAGE_SIZE = (224, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f00abc",
   "metadata": {},
   "source": [
    "We need to decode the byte strings representing JPEG images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6b2635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, IMAGE_SIZE)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c94190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tfrecord(example):\n",
    "    tfrecord_format = {\n",
    "            \"image_raw\": tf.io.FixedLenFeature([], tf.string),\n",
    "            \"label\": tf.io.FixedLenFeature([], tf.int64)\n",
    "\n",
    "    }\n",
    "    \n",
    "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
    "\n",
    "    \n",
    "    image = decode_image(example[\"image_raw\"])\n",
    "    label = tf.cast(example[\"label\"], tf.int32)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a22d41",
   "metadata": {},
   "source": [
    "We construct data sets by shuffling, prefetching and batching the data read from TFRecords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298b7c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(fn):\n",
    "    dataset = tf.data.TFRecordDataset(fn)\n",
    "    \n",
    "    dataset = dataset.map(read_tfrecord, num_parallel_calls=8)\n",
    "    \n",
    "    dataset = dataset.shuffle(1024)\n",
    "    dataset = dataset.prefetch(buffer_size=64)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42097e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(tfrecord_train_fn)\n",
    "test_dataset = load_dataset(tfrecord_test_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ad3273",
   "metadata": {},
   "source": [
    "**Plot some images:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add1b918",
   "metadata": {},
   "source": [
    "As you know very well by now, it's always a good idea to have a look at the data after each step. Here's a few images from the batches extracted from the training and test datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06506c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(image_batch, label_batch):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for n in range(25):\n",
    "        ax = plt.subplot(5, 5, n + 1)\n",
    "        plt.imshow(image_batch[n] / 255.0)\n",
    "        plt.title(labels_dict[label_batch[n]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6695f707",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120d0991",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(image_batch.numpy(), label_batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af53b3ff",
   "metadata": {},
   "source": [
    "From the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feed8a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(iter(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7f1358",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(image_batch.numpy(), label_batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724ad685",
   "metadata": {},
   "source": [
    "# Train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02604f51",
   "metadata": {},
   "source": [
    "Now we can train a model. We'll follow the setup in notebook `1.1`, with some minor modifications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d2dd94",
   "metadata": {},
   "source": [
    "This time we'll try out a learning rate schedule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e4979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.01\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=20, decay_rate=0.96, staircase=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6653e08",
   "metadata": {},
   "source": [
    "We'll set up two different base models: an Xception model and a ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4a7304",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_xc = tf.keras.applications.Xception(\n",
    "        input_shape=(*IMAGE_SIZE, 3), include_top=False, weights=\"imagenet\"\n",
    "    )\n",
    "\n",
    "preprocess_input_xc = keras.applications.xception.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455a657b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_rn = keras.applications.resnet.ResNet50(\n",
    "         input_shape=(*IMAGE_SIZE,3), include_top=False, weights=\"imagenet\")\n",
    "\n",
    "preprocess_input_rn = keras.applications.resnet.preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77081a40",
   "metadata": {},
   "source": [
    "The below model is essentially a copy of the one in notebook `1.1`. Consult that notebook for additional details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea21bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(base_model, preprocess_input):\n",
    "    \n",
    "    base_model.trainable = False\n",
    "\n",
    "    inputs = keras.layers.Input([*IMAGE_SIZE, 3])\n",
    "    \n",
    "    # Data augmentation\n",
    "    x = keras.layers.Resizing(224, 224)(inputs)\n",
    "    x = keras.layers.RandomFlip(\"horizontal\")(x)\n",
    "    x = keras.layers.RandomRotation(0.1)(x)\n",
    "    x = keras.layers.RandomZoom(0.1)(x)\n",
    "    x = keras.layers.RandomContrast(factor=0.01)(x) \n",
    "    \n",
    "    # Preprocess according to the base model\n",
    "    x = preprocess_input(x)\n",
    "    \n",
    "    # Pass through the base model\n",
    "    x = base_model(x)\n",
    "    \n",
    "    # Head\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = keras.layers.BatchNormalization(axis=-1)(x)\n",
    "    x = keras.layers.Dropout(rate=0.25)(x)\n",
    "    x = keras.layers.Dense(512, activation=\"relu\")(x)\n",
    "    x = keras.layers.BatchNormalization(axis=-1)(x)\n",
    "    x = keras.layers.Dropout(rate=0.5)(x)\n",
    "\n",
    "    outputs = keras.layers.Dense(5, activation=\"softmax\")(x)\n",
    "\n",
    "    # Create and compile the model\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        metrics=\"accuracy\",\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409d4b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model(base_model=base_model_rn, preprocess_input=preprocess_input_rn)\n",
    "#tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f35c630",
   "metadata": {},
   "source": [
    "Let's train it. We'll add a TensorBoard callback. More on that below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6391f558",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=\"./logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbda7da1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=3,\n",
    "    validation_data=test_dataset,\n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf1e395",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d37a35",
   "metadata": {},
   "source": [
    "It's useful to follow along with the training process, visualize and inspect the trained model using TensorBoard: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bd0584",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ab0529",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2d8662",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beea8180",
   "metadata": {},
   "source": [
    "Now we can evaluate the model in all the ways discussed previously. Here we simply compute the accuract on the validation data plot some predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780ece15",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4cd6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loss: {loss}\\n Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de810224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch_predictions(image_batch, label_batch):\n",
    "    fig = plt.figure(figsize=(12,12))\n",
    "    fig.suptitle(\"prediction / actual\", y=0.93)\n",
    "    for n in range(25):\n",
    "        ax = plt.subplot(5, 5, n + 1)\n",
    "        plt.imshow(image_batch[n] / 255.0)\n",
    "        img_array = tf.expand_dims(image_batch[n], axis=0)\n",
    "        title = f\"{labels_dict[model.predict(img_array)[0].argmax()]}/ {labels_dict[label_batch.numpy()[n]]}\"\n",
    "        plt.title(title, fontsize=10)\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa2c170",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(iter(test_dataset))\n",
    "\n",
    "show_batch_predictions(image_batch, label_batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
