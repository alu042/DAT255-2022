{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b035609",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bbfa1a",
   "metadata": {},
   "source": [
    "This notebook is a companion to `1.0-flowers-in-fastai.ipynb` meant to introduce TensorFlow and Keras to those who already know fastai."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76f439f",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ab8cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d49585",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('path.pkl', 'rb') as f:\n",
    "    path = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285294e8",
   "metadata": {},
   "source": [
    "# Dataset and dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b6da63",
   "metadata": {},
   "source": [
    "We load our flowers using `image_dataset_from_directory`, similarly to what we did using a DataBlock in fastai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f984291",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=(224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83813a04",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "flowers_train = keras.preprocessing.image_dataset_from_directory(path, \n",
    "                                                                    batch_size=64, \n",
    "                                                                    image_size=image_size,\n",
    "                                                                    validation_split=0.2,\n",
    "                                                                    seed = 42,\n",
    "                                                                    subset=\"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71770b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "flowers_val = keras.preprocessing.image_dataset_from_directory(path, \n",
    "                                                                batch_size=64, \n",
    "                                                                image_size=image_size,\n",
    "                                                                validation_split=0.2,\n",
    "                                                                seed = 42,\n",
    "                                                                subset=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a54015",
   "metadata": {},
   "outputs": [],
   "source": [
    "flowers_val.class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6702354",
   "metadata": {},
   "source": [
    "Here's a few elements from the first batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36517b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in flowers_train.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(flowers_train.class_names[int(labels[i])])\n",
    "        plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec21680",
   "metadata": {},
   "source": [
    "# Train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97ea429",
   "metadata": {},
   "source": [
    "In fastai we used a `cnn_learner` with a pretrained ResNet model as the base model. Let's do it in a similar way with Keras. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8adb7a",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dc86ef",
   "metadata": {},
   "source": [
    "We'll need some data augmentation. In Keras, we can add data augmentation by adding layers to the model. \n",
    "\n",
    "Here are some examples of data augmentation layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c12b725",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Resizing(224, 224),\n",
    "        keras.layers.RandomFlip(\"horizontal\"),\n",
    "        keras.layers.RandomRotation(0.1),\n",
    "        keras.layers.RandomZoom(0.1),\n",
    "        keras.layers.RandomContrast(factor=0.01)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548e100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in flowers_train.take(1):\n",
    "    for i in range(9):\n",
    "        augmented_images = data_augmentation(images, training=True)\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "        plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c158d901",
   "metadata": {},
   "source": [
    "## Instantiate a base model and load pre-trained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca5851d",
   "metadata": {},
   "source": [
    "We cut off the top part of the model (we'll insert our own head later):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf51079",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = keras.applications.resnet.ResNet50(weights=\"imagenet\",\n",
    "                                                   input_shape=image_size + (3,), \n",
    "                                                   include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6f3c5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#keras.utils.plot_model(resnet_model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e04d3b5",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a63daf5",
   "metadata": {},
   "source": [
    "As the model is pre-trained on a dataset with specific properties (ImageNet) we need to preprocess our data to make it resemble the original data set. We'll do that by inserting a preprocessing layer at the beginning of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82acf5f7",
   "metadata": {},
   "source": [
    "### Extra: check the effect of preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16f3f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=image_size + (3,))\n",
    "outputs = keras.applications.resnet.preprocess_input(inputs)\n",
    "preprocess_m = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1251cc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_m.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e04491",
   "metadata": {},
   "source": [
    "Here's a batch of images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d88a478",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(flowers_train.take(1)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f89f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8120f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdd3d3f",
   "metadata": {},
   "source": [
    "Here's the batch after being fed through these preprocessing layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c4d8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_pred = preprocess_m.predict(batch)\n",
    "batch_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd80bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_pred.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5978bd33",
   "metadata": {},
   "source": [
    "## Add a new head to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2313634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs are images (tensors) of a particular size\n",
    "inputs = keras.Input(image_size + (3,))\n",
    "\n",
    "# Data augmentation\n",
    "x = keras.layers.Resizing(224, 224)(inputs)\n",
    "x = keras.layers.RandomFlip(\"horizontal\")(x)\n",
    "x = keras.layers.RandomRotation(0.1)(x)\n",
    "x = keras.layers.RandomZoom(0.1)(x)\n",
    "x = keras.layers.RandomContrast(factor=0.01)(x)               \n",
    "\n",
    "# We preprocess the tensors to be compatible with the pretrained base model:\n",
    "x = keras.applications.resnet.preprocess_input(x)\n",
    "\n",
    "# Base model:\n",
    "x = resnet_model(x, training=False)\n",
    "\n",
    "# Custom head:\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.BatchNormalization(axis=-1)(x)\n",
    "x = keras.layers.Dropout(rate=0.25)(x)\n",
    "x = keras.layers.Dense(512, activation=\"relu\")(x)\n",
    "x = keras.layers.BatchNormalization(axis=-1)(x)\n",
    "x = keras.layers.Dropout(rate=0.5)(x)\n",
    "\n",
    "# Outputs\n",
    "outputs = keras.layers.Dense(5, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670b82e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b9f0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8691c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad53a7d2",
   "metadata": {},
   "source": [
    "## Train the head of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c28c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = flowers_train.prefetch(buffer_size=64)\n",
    "val_ds = flowers_val.prefetch(buffer_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c784036",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d04a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "             loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "             metrics = \"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d9afdd",
   "metadata": {},
   "source": [
    "Note: if we wanted to stick closer to fastai ideas, we could use cyclical learning rates from [TensorFlow addons](https://www.tensorflow.org/addons/tutorials/optimizers_cyclicallearningrate), and also a [learning rate finder](https://pyimagesearch.com/2019/08/05/keras-learning-rate-finder/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1500be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow_addons.optimizers import CyclicalLearningRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a4c1ef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(train_ds, epochs=3, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740c8e74",
   "metadata": {},
   "source": [
    "## Unfreeze and fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ab29cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd158da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(1e-5),\n",
    "             loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False), \n",
    "             metrics = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa0a4bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(train_ds, epochs=2, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a6189d",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db3d712",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(flowers_val)\n",
    "print(\"Accuracy: \", acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
