{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0854b1c3-1f64-4a0d-a968-7e4693333562",
   "metadata": {},
   "source": [
    "Alexander S. Lundervold, 20.04.22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc0ed00-51f7-4cc1-806a-647392636110",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183080ca-ab3b-49fa-9fbd-2aa8456b85b4",
   "metadata": {},
   "source": [
    "Now we've come to the (small) part of the machine learning engineering pipeline where the actual machine learning takes place. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d683768c-bdd6-4f5a-ad0f-0d17b57c8051",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"https://dl.acm.org/doi/10.5555/2969442.2969519\"><img width=60% src=\"assets/mlengineering.png\"></a><br>\n",
    "<span style=\"font-size:10px\">Figure from <a href=\"https://dl.acm.org/doi/10.5555/2969442.2969519\">Sculley et.al., Hidden technical debt in Machine learning systems, 2015</a></span></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9538aa-d5c5-4099-a3a6-d4073644de2b",
   "metadata": {},
   "source": [
    "We've done the **data ingestion** (`ExampleGen`), the **data validation** (`StatisticsGen`, `SchemaGen`, `ExampleValidator`), and the **data preprocessing** (`Transform`), and are ready to move on to **model training**, then **model analysis and validation**, before, finally, **model deployment**.\n",
    "\n",
    "In this notebook, we'll take a look at **hyperparameter tuning** and **model training**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5b431c-7608-4e98-a62c-7c57eb2167ea",
   "metadata": {},
   "source": [
    "## `Trainer` and `Tuner`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1f8214-a6a1-4366-8fca-05ab59d1cb0f",
   "metadata": {},
   "source": [
    "In TensorFlow Extended, we can use the `Trainer` and `Tuner` components for training and using models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7008d66a-6f77-499d-8ce3-ced0aed2f318",
   "metadata": {},
   "source": [
    "Our goal is to construct the following pipeline:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37941b73-e8ea-426d-a5c8-325fd4096d3c",
   "metadata": {},
   "source": [
    "<img width=100% src=\"assets/pipeline_4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f31d15-b9ed-48c5-86a0-26e2bd2c1a3e",
   "metadata": {},
   "source": [
    "The inputs to the `Trainer` component will be the preprocessing graph and the transformed example artifacts from the `Transform` component, the data schema (that we defined using `SchemaGen`), and a user-provided module file that specifies the model and training logic. \n",
    "\n",
    "The `Tuner` component takes as its inputs the transformed examples and a module file that specifies the model and the tuning logic, including the hyperparameter space over which to search, and the objective to be used during the search. When executed, it produces the best results found during the search. These can then be consumed by the `Trainer`.\n",
    "\n",
    "As always, you should consult the TFX guide for additional details: https://www.tensorflow.org/tfx/guide/tuner<br>\n",
    "https://www.tensorflow.org/tfx/guide/trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c1b422-5f85-4b01-bcd9-bd591950eb63",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0383724d-d88c-40ba-b5ae-7486476290c1",
   "metadata": {},
   "source": [
    "Import basic libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9775b3-64b5-44a4-a365-6cdcd7c35c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a150e374-b9d6-497f-8ab4-d481cb562478",
   "metadata": {},
   "source": [
    "Check whether we're running on Colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ee03ae-1be2-448e-8b19-5b50474d9f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import colab\n",
    "    colab=True\n",
    "except:\n",
    "    colab=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0225f8-5468-4f45-ad8b-effbe0da9a44",
   "metadata": {},
   "source": [
    "Set up data directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b20ab30-ee4e-409e-80f9-1cbd6d70c04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('./gdrive')\n",
    "    DATA = Path('./gdrive/MyDrive/ColabData/petfinder-mini/csv')\n",
    "else:\n",
    "    NB_DIR = Path.cwd()\n",
    "    DATA = NB_DIR/'..'/'data'/'petfinder-mini'/'csv'\n",
    "    \n",
    "SPLIT_DATA = DATA/'..'/'split_csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93815b38-50da-46d3-85fc-9140045ce414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# To use a specific GPU in a multi-GPU setup\n",
    "# You will want to remove this if you're using a single GPU system\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40fcef4-30ba-4a61-8fae-88a308c118b9",
   "metadata": {},
   "source": [
    "Install TFX and import components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d511ec-f3b2-41e6-9807-0fa26d5c753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab:\n",
    "    !pip install -U tfx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bdaa12-34ed-4219-b1e8-cad3b2c07458",
   "metadata": {},
   "source": [
    "> If on Colab, restart the runtime after running the above cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f48fb44-2066-4f4b-9972-8b68c251b0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb21c0cf-f715-4e08-bda8-e51f199ebaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tfx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb8d778-8ed4-4d40-ae1d-9a13c0980629",
   "metadata": {},
   "source": [
    "Set up the interactive context for running TFX components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde7b166-7b70-4564-948a-a886bfcd4788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cf7506-b2b5-44d2-b9e8-973a229ed35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = InteractiveContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afb10ff-ba64-4832-bef8-3e8c4a4ad67d",
   "metadata": {},
   "source": [
    "# Recreate the previous pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80b959b-8f4d-4cb3-841f-6d6160622657",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.components import CsvExampleGen\n",
    "from tfx.components import StatisticsGen\n",
    "from tfx.components import SchemaGen\n",
    "from tfx.components import ExampleValidator\n",
    "from tfx.components import Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef020065-9531-4916-b17f-67e6bc52b922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate examples\n",
    "example_gen = CsvExampleGen(input_base=str(DATA)+'/')\n",
    "\n",
    "# Generate statistics\n",
    "statistics_gen = StatisticsGen(examples=example_gen.outputs['examples'])\n",
    "\n",
    "# Automatic data schema (in a more realistic setting we would have \n",
    "# used a manually modified schema saved to disk)\n",
    "schema_gen = SchemaGen(statistics=statistics_gen.outputs['statistics'])\n",
    "\n",
    "# Validate examples\n",
    "example_validator = tfx.components.ExampleValidator(\n",
    "    statistics=statistics_gen.outputs['statistics'],\n",
    "    schema=schema_gen.outputs['schema'])\n",
    "\n",
    "# Preprocess\n",
    "pets_transform_file = 'pets_transforms.py'\n",
    "\n",
    "transform = Transform(\n",
    "    examples=example_gen.outputs['examples'],\n",
    "    schema=schema_gen.outputs['schema'],\n",
    "    module_file=os.path.abspath(pets_transform_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5b0597-ae94-422f-9155-5605715a05f9",
   "metadata": {},
   "source": [
    "## Run the components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bf0304-5190-4531-815f-d2e342aa55cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for component in [example_gen, statistics_gen, schema_gen, example_validator, transform]:\n",
    "    context.run(component)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e9a0b0-98f8-46b7-aa58-935a0da17968",
   "metadata": {},
   "source": [
    "# Set up the model, tuning and training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97961ad8-1130-46b0-8d8e-723089840d17",
   "metadata": {},
   "source": [
    "As we did in the previous notebook, we'll follow the example in Hapke & Nelson, Building Machine Learning Pipelines: [https://github.com/Building-ML-Pipelines/building-machine-learning-pipelines/blob/main/components/module.py](https://github.com/Building-ML-Pipelines/building-machine-learning-pipelines/blob/main/components/module.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3dae15-de36-43cd-86e6-dcf5f4caaedc",
   "metadata": {},
   "source": [
    "The basic idea of our model is to have the preprocessed features go through a simple one-layer neural network, except the text feature (`Description`) which will be passed to a pretrained NLP model that extracts embeddings. We'll use the Universal Sentence Encoder from the TensorFlow Hub: https://tfhub.dev/google/universal-sentence-encoder/4. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3125acf-48b0-4c51-a8f8-23aef22b7f9a",
   "metadata": {},
   "source": [
    "Here's an illustration of our model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49adddb2-a922-41b1-9ee9-cb6c94cc1f76",
   "metadata": {},
   "source": [
    "![](model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0853df-5c87-4954-b5b7-c7c30ba844a5",
   "metadata": {},
   "source": [
    "> Note that in practice one would make an effort to find a good model setup. This can be used as a possible starting point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345ba173-d4e4-4f19-9ed0-9cb8ae0c92cd",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5205e13-6b75-4c73-8468-6b69bfeddd02",
   "metadata": {},
   "source": [
    "We will illustrate how one can set up hyperparameter tuning using the Tuner component from TFX. The Tuner component needs a `tuner_fn` and the Trainer component a `run_fn`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89158941-991f-4c7c-bd97-91147fbb67bd",
   "metadata": {},
   "source": [
    "## Create a module file for training and tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cb040e-2ff3-40a7-81e9-6b4b761976f6",
   "metadata": {},
   "source": [
    "This module has quite a large number of components. Go through this very carefully to see that you understand what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294d936e-4b05-4e8e-8df9-5093d4caabf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile module.py\n",
    "\n",
    "import os\n",
    "# To train on a specific GPU in a multi-GPU setup\n",
    "# You will want to remove this if you're using a single GPU system\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras_tuner\n",
    "from tfx import v1 as tfx\n",
    "import tensorflow_transform as tft\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "\n",
    "# We grab the features from our pets_transform module\n",
    "import pets_transforms\n",
    "_ONE_HOT_FEATURES = pets_transforms.ONE_HOT_FEATURES\n",
    "_NUMERICAL_FEATURES = pets_transforms.NUMERICAL_FEATURES\n",
    "_TEXT_FEATURES = pets_transforms.TEXT_FEATURES\n",
    "_LABEL_KEY = pets_transforms.LABEL_KEY\n",
    "\n",
    "_transformed_name = pets_transforms._transformed_name\n",
    "\n",
    "\n",
    "############################################################\n",
    "# Define the model and its hyperparameters\n",
    "############################################################\n",
    "\n",
    "def _get_hyperparameters() -> keras_tuner.HyperParameters:\n",
    "    \"\"\"Returns hyperparameters for building Keras model.\n",
    "    Copied from \n",
    "    https://github.com/tensorflow/tfx/blob/master/tfx/examples/penguin/penguin_utils_keras.py\n",
    "    \"\"\"\n",
    "    hp = keras_tuner.HyperParameters()\n",
    "    # Defines search space.\n",
    "    hp.Choice('learning_rate', [1e-2, 1e-3], default=1e-2)\n",
    "    hp.Int('num_nontext_layers', 1, 3, default=2)\n",
    "    return hp\n",
    "\n",
    "\n",
    "\n",
    "def get_model(hparams: keras_tuner.HyperParameters) -> tf.keras.models.Model:\n",
    "    \"\"\"\n",
    "    Creates a Keras model using the specified hyperparameters\n",
    "    \n",
    "    Returns:\n",
    "        A model as a Keras object\n",
    "    \"\"\"\n",
    "    \n",
    "    # We'll store all the input features except the text feature here:\n",
    "    input_features = []\n",
    "    \n",
    "    \n",
    "    for key, dim in _ONE_HOT_FEATURES.items():\n",
    "        input_features.append(\n",
    "            tf.keras.Input(shape=(dim+1, ), name=_transformed_name(key))\n",
    "        )\n",
    "        \n",
    "    for feature in _NUMERICAL_FEATURES:\n",
    "        input_features.append(\n",
    "            tf.keras.Input(shape=(1, ), name=_transformed_name(feature))\n",
    "        )\n",
    "        \n",
    "    # Text feature\n",
    "    input_texts = []\n",
    "    for key in _TEXT_FEATURES.keys():\n",
    "        input_texts.append(\n",
    "            tf.keras.Input(shape=(1,), name=_transformed_name(key), dtype=tf.string)\n",
    "        )\n",
    "\n",
    "        \n",
    "    # Embedding the text feature\n",
    "    MODULE_URL = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "    embed = hub.KerasLayer(MODULE_URL)\n",
    "    reshaped_description = tf.reshape(input_texts[0], [-1])\n",
    "    embed_description = embed(reshaped_description)\n",
    "    \n",
    "    # Construct the subgraph for the text features\n",
    "    text_model = tf.keras.layers.Reshape((512,), input_shape=(1, 512))(embed_description)\n",
    "    text_model = tf.keras.layers.Dense(16, activation=\"relu\")(text_model)\n",
    "    \n",
    "    # Subgraph for the other features\n",
    "    other_model = tf.keras.layers.concatenate(input_features)\n",
    "    for _ in range(int(hparams.get('num_nontext_layers'))):\n",
    "        other_model = tf.keras.layers.Dense(8, activation=\"relu\")(other_model)\n",
    "    \n",
    "    # Stitch the two model parts together\n",
    "    both = tf.keras.layers.concatenate([text_model, other_model])\n",
    "    both = tf.keras.layers.Dropout(.7)(both)\n",
    "\n",
    "    # Produce output predictions\n",
    "    output = tf.keras.layers.Dense(5, activation=\"softmax\")(both)\n",
    "    \n",
    "    # Define the inputs\n",
    "    inputs = input_features + input_texts\n",
    "    \n",
    "    # Create the model\n",
    "    keras_model = tf.keras.models.Model(inputs, output)\n",
    "    \n",
    "    keras_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(hparams.get('learning_rate')),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Save a plot of the model\n",
    "    tf.keras.utils.plot_model(keras_model, show_shapes=True, rankdir=\"LR\")\n",
    "    \n",
    "    return keras_model\n",
    "\n",
    "\n",
    "############################################################\n",
    "# Define an input function to generate features and label\n",
    "############################################################\n",
    "\n",
    "# This is taken from Hapke & Nelson and the TFX documentation (links below)\n",
    "\n",
    "def _gzip_reader_fn(filenames):\n",
    "    \"\"\"Small utility returning a record reader that can read gzip'ed files.\"\"\"\n",
    "    return tf.data.TFRecordDataset(filenames, compression_type=\"GZIP\")\n",
    "\n",
    "\n",
    "def _get_serve_tf_examples_fn(model, tf_transform_output):\n",
    "    \"\"\"Returns a function that parses a serialized tf.Example.\n",
    "    From \n",
    "    https://github.com/tensorflow/tfx/blob/master/tfx/examples/mnist/mnist_utils_native_keras.py\n",
    "    \"\"\"\n",
    "\n",
    "    model.tft_layer = tf_transform_output.transform_features_layer()\n",
    "\n",
    "    @tf.function\n",
    "    def serve_tf_examples_fn(serialized_tf_examples):\n",
    "        \"\"\"Returns the output to be used in the serving signature.\"\"\"\n",
    "        feature_spec = tf_transform_output.raw_feature_spec()\n",
    "        feature_spec.pop(_LABEL_KEY)\n",
    "        parsed_features = tf.io.parse_example(serialized_tf_examples, feature_spec)\n",
    "\n",
    "        transformed_features = model.tft_layer(parsed_features)\n",
    "\n",
    "        outputs = model(transformed_features)\n",
    "        return {\"outputs\": outputs}\n",
    "\n",
    "    return serve_tf_examples_fn\n",
    "\n",
    "\n",
    "def _input_fn(file_pattern, tf_transform_output, batch_size=64):\n",
    "    \"\"\"Generates features and label for tuning/training.\n",
    "    Args:\n",
    "    file_pattern: input tfrecord file pattern.\n",
    "    tf_transform_output: A TFTransformOutput.\n",
    "    batch_size: representing the number of consecutive elements of returned\n",
    "      dataset to combine in a single batch\n",
    "      Returns:\n",
    "        A dataset that contains (features, indices) tuple where features is a\n",
    "          dictionary of Tensors, and indices is a single Tensor of\n",
    "          label indices.\n",
    "          \n",
    "    See also \n",
    "    https://github.com/tensorflow/tfx/blob/master/tfx/examples/mnist/mnist_utils_native_keras_base.py\n",
    "    \"\"\"\n",
    "    transformed_feature_spec = tf_transform_output.transformed_feature_spec().copy()\n",
    "\n",
    "    dataset = tf.data.experimental.make_batched_features_dataset(\n",
    "        file_pattern=file_pattern,\n",
    "        batch_size=batch_size,\n",
    "        features=transformed_feature_spec,\n",
    "        reader=_gzip_reader_fn,\n",
    "        label_key=_transformed_name(_LABEL_KEY),\n",
    "    )\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "############################################################\n",
    "# Define the hyperparameter tuner\n",
    "############################################################\n",
    "# Tuner will call the following function.\n",
    "# Based on https://github.com/tensorflow/tfx/blob/master/tfx/examples/penguin/penguin_utils_keras.py\n",
    "\n",
    "def tuner_fn(fn_args: tfx.components.FnArgs) -> tfx.components.TunerFnResult:\n",
    "    \"\"\"Build the tuner using the KerasTuner API\n",
    "    \"\"\"\n",
    "    \n",
    "    tuner = keras_tuner.RandomSearch(\n",
    "          get_model,\n",
    "          max_trials=6,\n",
    "          hyperparameters=_get_hyperparameters(),\n",
    "          allow_new_entries=False,\n",
    "          objective=keras_tuner.Objective('val_sparse_categorical_accuracy', 'max'),\n",
    "          directory=fn_args.working_dir,\n",
    "          project_name='petfinder_tuning')\n",
    "    \n",
    "    transform_graph = tft.TFTransformOutput(fn_args.transform_graph_path)\n",
    "\n",
    "    train_dataset = _input_fn(\n",
    "        fn_args.train_files,\n",
    "        transform_graph,\n",
    "        batch_size=64)\n",
    "\n",
    "    eval_dataset = _input_fn(\n",
    "        fn_args.eval_files,\n",
    "        transform_graph,\n",
    "        batch_size=64)\n",
    "\n",
    "    return tfx.components.TunerFnResult(\n",
    "        tuner=tuner,\n",
    "        fit_kwargs={\n",
    "            'x': train_dataset,\n",
    "            'validation_data': eval_dataset,\n",
    "            'steps_per_epoch': fn_args.train_steps,\n",
    "            'validation_steps': fn_args.eval_steps\n",
    "      })\n",
    "\n",
    "\n",
    "############################################################\n",
    "# Define the training function\n",
    "############################################################\n",
    "# Trainer will call this function.\n",
    "\n",
    "def run_fn(fn_args: tfx.components.FnArgs):\n",
    "    \"\"\"Train the model based on given args.\n",
    "    Args:\n",
    "    fn_args: Holds args used to train the model as name/value pairs.\n",
    "    \"\"\"\n",
    "    tf_transform_output = tft.TFTransformOutput(fn_args.transform_output)\n",
    "\n",
    "    train_dataset = _input_fn(fn_args.train_files, tf_transform_output, batch_size=64)\n",
    "    eval_dataset = _input_fn(fn_args.eval_files, tf_transform_output, batch_size=64)\n",
    "    \n",
    "    # Grab hyperparameters\n",
    "    hparams = _get_hyperparameters()\n",
    "\n",
    "    # Define the model\n",
    "    model = get_model(hparams)\n",
    "\n",
    "    # Log to TensorBoard\n",
    "    log_dir = os.path.join(os.path.dirname(fn_args.serving_model_dir), \"logs\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=log_dir, update_freq=\"batch\"\n",
    "    )\n",
    "    callbacks = [tensorboard_callback]\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        epochs=5,\n",
    "        steps_per_epoch=fn_args.train_steps,\n",
    "        validation_data=eval_dataset,\n",
    "        validation_steps=fn_args.eval_steps,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "    \n",
    "    # Save the model    \n",
    "    signatures = {\n",
    "        \"serving_default\": _get_serve_tf_examples_fn(\n",
    "            model, tf_transform_output\n",
    "        ).get_concrete_function(\n",
    "            tf.TensorSpec(shape=[None], dtype=tf.string, name=\"examples\")\n",
    "        ),\n",
    "    }\n",
    "    model.save(fn_args.serving_model_dir, save_format=\"tf\", signatures=signatures)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a46676f-2531-43ce-ac21-cb9fa9e1b0bd",
   "metadata": {},
   "source": [
    "## Search for hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1938364-cebe-4f2d-8f59-2352b3fef750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.components import Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ed2b85-e8d0-4839-a3c8-0bce1817b7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.proto import trainer_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcc77b8-cde0-4b9f-ac4b-03d8b7ad2d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As training takes some time we'll only use a few steps\n",
    "train_steps = 200\n",
    "eval_steps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a26315-dcc0-4a22-a83d-cdb5c70e9185",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = tfx.components.Tuner(\n",
    "    module_file=os.path.abspath('module.py'),\n",
    "    examples=transform.outputs['transformed_examples'],\n",
    "    transform_graph=transform.outputs['transform_graph'],\n",
    "    train_args=trainer_pb2.TrainArgs(num_steps=train_steps),\n",
    "    eval_args=trainer_pb2.EvalArgs(num_steps=eval_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bd77c6-4fd4-49d1-9b72-b1be47b565f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.run(tuner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba65005-4fb9-4d53-a84c-4b2d29d223ee",
   "metadata": {},
   "source": [
    "## Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1f4245-90d4-4ff1-ac91-52630e926667",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.components import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b46a71-efd7-4d8e-a1f4-8869395fc57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As training takes some time we'll only use a few steps\n",
    "train_steps = 200\n",
    "eval_steps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44c067a-a180-42fc-9a10-a4b897f9eb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    module_file=os.path.abspath('module.py'),\n",
    "    transformed_examples=transform.outputs['transformed_examples'],\n",
    "    schema=schema_gen.outputs['schema'],\n",
    "    transform_graph=transform.outputs['transform_graph'],\n",
    "    train_args=trainer_pb2.TrainArgs(splits=['train'], num_steps=train_steps),\n",
    "    eval_args=trainer_pb2.EvalArgs(splits=['eval'], num_steps=eval_steps)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50966efe-ddc6-4282-a8aa-3ea8a86c20ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.run(trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f28a30a-2c5c-424a-b561-76ab327b54b8",
   "metadata": {},
   "source": [
    "## Using TensorBoard to inspect and monitor the training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a904d8-5db3-4ff0-b2b1-6ed431bbd37b",
   "metadata": {},
   "source": [
    "The logs from our training process was stored as an output artifact:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe331fe-99eb-4004-8d4f-3c402ba724a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.outputs['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8245ec8d-69ef-4295-8425-4dcf3104b9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = trainer.outputs['model'].get()[0].uri\n",
    "model_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7e22b9-2c97-40fd-acd3-2f2d35beb1d5",
   "metadata": {},
   "source": [
    "We find the logs in the `logs` subdirectory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8ca8fc-0758-443a-944e-cc0b66709f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db6bdb2-90b1-43f5-898b-a92699f39cb6",
   "metadata": {},
   "source": [
    "We can use TensorBoard directly in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f92613-336e-4ba8-ae36-e6cde546c8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {model_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767d4f50-f726-4320-9b7e-6a258f55bc17",
   "metadata": {},
   "source": [
    "# What have we done so far?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b32a795-e3c5-4647-b368-bdebd27ff00d",
   "metadata": {},
   "source": [
    "Here's our current pipeline:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512e937b-b9d5-4985-97d5-f6153ff780b0",
   "metadata": {},
   "source": [
    "<img width=100% src=\"assets/pipeline_4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592de93d-db2a-406b-b33f-a5ccb8c891b8",
   "metadata": {},
   "source": [
    "# What's next?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12417e08-9d5d-464c-ba62-6c85adf770c1",
   "metadata": {},
   "source": [
    "The next step is to do **model analysis**. For this, we'll use the **[TensorFlow Model Analysis](https://www.tensorflow.org/tfx/tutorials/model_analysis/tfma_basic)** library (for manual inspection) and look at the TFX components **Evaluator**, **InfraValidator**, and **Pusher** (for automatic model analysis as part of our pipeline)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfx]",
   "language": "python",
   "name": "conda-env-tfx-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
