{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad7cd9c7-4232-422f-823e-3b268efad842",
   "metadata": {},
   "source": [
    "Alexander S. Lundervold, 20.04.22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c999e70-e9b3-4de3-a042-5da46eb48110",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89ea0da-7683-43f6-b29e-3ebf44d1b2e5",
   "metadata": {},
   "source": [
    "The **Transform** component will grab the artifacts produced by our `ExampleGen` (our examples) and `SchemaGen` (the data schema). It will produce two artifacts: a computational graph (a TensorFlow graph) containing the preprocessing steps and the transformed examples stored as TFRecords (together with their statistics). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5461400-f750-4355-a048-59d62a6b255e",
   "metadata": {},
   "source": [
    "Note that when using Transform, the preprocessing steps become part of the TensorFlow graph. When the TensorFlow graph is deployed, all the preprocessing steps will be performed on the server, making it easier (and less error-prone) to construct client-side setups and avoiding pitfalls when going from training to serving models. \n",
    "\n",
    "The computations in TensorFlow Transform are implemented in the high-performance, data-parallel processing framework [Apache Beam](https://beam.apache.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2ce92e-6440-4614-a6e9-2a4bee477e3e",
   "metadata": {},
   "source": [
    "See also the TFX guide about the Transform component: https://www.tensorflow.org/tfx/guide/transform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163315ed-33ac-4a3d-a746-eea637f6dd5b",
   "metadata": {},
   "source": [
    "This is what our pipeline will look like at the end of the notebook:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fc2cd7-f6ed-4a67-ae88-c06e48e1f636",
   "metadata": {},
   "source": [
    "<img width=60% src=\"assets/pipeline_3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62399240-9257-470f-a1f4-c1b085b3dfda",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1000d0-a091-441d-8ff4-ad2453c5a188",
   "metadata": {},
   "source": [
    "Import basic libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9775b3-64b5-44a4-a365-6cdcd7c35c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9678508d-2906-4f61-8071-b07f610dd0eb",
   "metadata": {},
   "source": [
    "Check whether we're running on Colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ee03ae-1be2-448e-8b19-5b50474d9f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import colab\n",
    "    colab=True\n",
    "except:\n",
    "    colab=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9b4a21-5598-48d1-941c-5ec9587b9d39",
   "metadata": {},
   "source": [
    "Set up data directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b20ab30-ee4e-409e-80f9-1cbd6d70c04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('./gdrive')\n",
    "    DATA = Path('./gdrive/MyDrive/ColabData/petfinder-mini/csv')\n",
    "else:\n",
    "    NB_DIR = Path.cwd()\n",
    "    DATA = NB_DIR/'..'/'data'/'petfinder-mini'/'csv'\n",
    "    \n",
    "SPLIT_DATA = DATA/'..'/'split_csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22f6a6f-e731-46c0-a674-7bd291b27eb5",
   "metadata": {},
   "source": [
    "Install TFX and import components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d511ec-f3b2-41e6-9807-0fa26d5c753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab:\n",
    "    !pip install -U tfx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ece276-7614-4376-8958-0fbcb3e71967",
   "metadata": {},
   "source": [
    "> If on Colab, restart the runtime after running the above cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63497eb-4eed-470d-9971-b60d143243ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80b959b-8f4d-4cb3-841f-6d6160622657",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.components import CsvExampleGen\n",
    "from tfx.components import StatisticsGen\n",
    "from tfx.components import SchemaGen\n",
    "from tfx.components import ExampleValidator\n",
    "from tfx.components import Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9490767a-3834-4f31-9844-8c58efb635c1",
   "metadata": {},
   "source": [
    "Set up the interactive context for running TFX components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde7b166-7b70-4564-948a-a886bfcd4788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cf7506-b2b5-44d2-b9e8-973a229ed35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = InteractiveContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de74891-8500-47eb-9d63-0c9888805b2e",
   "metadata": {},
   "source": [
    "# Recreate the previous pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb8c736",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.components import CsvExampleGen\n",
    "from tfx.components import StatisticsGen\n",
    "from tfx.components import SchemaGen\n",
    "from tfx.components import ExampleValidator\n",
    "from tfx.components import Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef020065-9531-4916-b17f-67e6bc52b922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate examples\n",
    "example_gen = CsvExampleGen(input_base=str(DATA)+'/')\n",
    "\n",
    "# Generate statistics\n",
    "statistics_gen = StatisticsGen(examples=example_gen.outputs['examples'])\n",
    "\n",
    "# Automatic data schema (in a more realistic setting we would have \n",
    "# used a manually modified schema)\n",
    "schema_gen = SchemaGen(statistics=statistics_gen.outputs['statistics'])\n",
    "\n",
    "# Validate examples\n",
    "example_validator = tfx.components.ExampleValidator(\n",
    "    statistics=statistics_gen.outputs['statistics'],\n",
    "    schema=schema_gen.outputs['schema'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a01b4b-d38a-4a4c-a75f-42d2d4b9ca16",
   "metadata": {},
   "source": [
    "### Execute the components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787a2653-9a66-4d23-a472-6809d13281fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.run(example_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e5d5ad-1da1-4a8e-aab6-673ba6f55c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.run(statistics_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d391e239-b989-480c-8ee1-e9f6c4160912",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.run(schema_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bd5341-f1d9-4ce0-8838-7b3ead5bf59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.run(example_validator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adda6223-1162-4069-8370-cd43afc92cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.show(schema_gen.outputs['schema'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdb057b-f550-4e57-9678-ff47b77f9cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.show(example_validator.outputs['anomalies'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a843880c-9e96-4d17-9ddf-41ab37ec4b3a",
   "metadata": {},
   "source": [
    "Now we've recreated the pipeline from the previous notebook:\n",
    "\n",
    "<img src='assets/pipeline_2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6254c3-d4ea-4884-acfe-30e4e3f2baf7",
   "metadata": {},
   "source": [
    "# The Transform component"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427249fd-a88b-40a5-8f05-def510581bb0",
   "metadata": {},
   "source": [
    "The data preprocessing will be done using the Transform component (which is based on the standalone library [TensorFlow Transform](https://www.tensorflow.org/tfx/transform/get_started))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2148675-5d4c-4c67-8877-58a64422a6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.components import Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb65b1e0-52e6-41d9-88de-21c704566a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#?Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af9f50d-aee1-4c64-a116-9456781a5151",
   "metadata": {},
   "source": [
    "To perform our preprocessing, we need to take a closer look at the dataset we're using. We have to preprocess the numerical, categorical, ordinal, text and other features in data type-specific ways. This typically requires some manual work, as we have to make a bunch of decisions about how to represent each feature. (However, it's possible to at least partially automate some of this. Some of you have for example seen the PyCaret library, and it's `setup` function that figures out workable preprocessing steps: https://pycaret.gitbook.io/docs/get-started/functions/initialize#setting-up-environment). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b2910f-85dc-4aa0-82b4-ad9894c67231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343f737f-29af-4cd1-9e05-68f5a5b8e852",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA/'petfinder-mini.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa3b68a-75de-4dab-ad0a-dcaac9feebf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52552e60-0ea8-4abf-bfe0-0050c57c4924",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f647348-87aa-4f05-a683-18b79cdb4914",
   "metadata": {},
   "source": [
    "Here's some descriptions that we can gather from looking at the data, reading the description on Kaggle [PetFinder.my Adoption Prediction](https://www.kaggle.com/c/petfinder-adoption-prediction/data), and consulting the TensorFlow catalog https://www.tensorflow.org/datasets/catalog/pet_finder. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedf90f7-efbf-4375-b842-da0fc569b178",
   "metadata": {},
   "source": [
    "* `Type` - Type of animal (Cat, Dog)\n",
    "* `Age` - Age of pet when listed, in months\n",
    "* `Breed1` - Primary breed of pet (Refer to BreedLabels dictionary)\n",
    "* `Gender` - Gender of pet (Male, Female)\n",
    "* `Color1` - Color 1 of pet (Black, Brown, Cream, Gray, Golden, White, Yellow)\n",
    "* `Color2` - Color 2 of pet ('White', 'Brown', 'No Color', 'Gray', 'Cream', 'Golden', 'Yellow')\n",
    "* `MaturitySize` - Size at maturity (Small, Medium, Large)\n",
    "* `FurLength` - Fur length (Short, Medium, Long)\n",
    "* `Vaccinated` - Pet has been vaccinated (Yes, No, Not Sure)\n",
    "* `Sterilized` - Pet has been spayed / neutered (Yes, No, Not Sure)\n",
    "* `Health` - Health Condition (Healthy, Minor Injury, Serious Injury, Not Specified)\n",
    "* `Fee` - Adoption fee (0 = Free)\n",
    "* `Description` - Profile write-up for this pet. The primary language used is English, with some in Malay or Chinese.\n",
    "* `PhotoAmt` - The total number of uploaded photos for each pet (numerical)\n",
    "* `AdoptionSpeed` - Categorical speed of adoption. Lower is faster. This is the value to predict. 0 - Pet was adopted on the same day as it was listed; 1 - Pet was adopted between 1 and 7 days (1st week) after being listed; 2 - Pet was adopted between 8 and 30 days (1st month) after being listed; 3 - Pet was adopted between 31 and 90 days (2nd & 3rd month) after being listed; 4 - No adoption after 100 days of being listed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef36a20-5773-4960-9457-f3357f129d0e",
   "metadata": {},
   "source": [
    "| Column          | Pet description               | Feature type   | Data type |\n",
    "| --------------- | ----------------------------- | -------------- | --------- |\n",
    "| `Type`          | Type of animal (`Dog`, `Cat`) | Categorical    | String    |\n",
    "| `Age`           | Age                           | Numerical      | Integer   |\n",
    "| `Breed1`        | Primary breed                 | Categorical    | String    |\n",
    "| `Color1`        | Color 1                       | Categorical    | String    |\n",
    "| `Color2`        | Color 2                       | Categorical    | String    |\n",
    "| `MaturitySize`  | Size at maturity              | Categorical    | String    |\n",
    "| `FurLength`     | Fur length                    | Categorical    | String    |\n",
    "| `Vaccinated`    | Pet has been vaccinated       | Categorical    | String    |\n",
    "| `Sterilized`    | Pet has been sterilized       | Categorical    | String    |\n",
    "| `Health`        | Health condition              | Categorical    | String    |\n",
    "| `Fee`           | Adoption fee                  | Numerical      | Integer   |\n",
    "| `Description`   | Profile write-up              | Text           | String    |\n",
    "| `PhotoAmt`      | Total uploaded photos         | Numerical      | Integer   |\n",
    "| `AdoptionSpeed` | Categorical speed of adoption | Classification | Integer   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f728f14e-bde5-47f9-9bad-a4ddc3e77f99",
   "metadata": {},
   "source": [
    "## Define a preprocessing function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5681dd1c-a2bc-45c1-a3bb-0e47b10f04a4",
   "metadata": {},
   "source": [
    "The preprocessing steps we want our Transform component to perform will have to be specified in a preprocessing function `preprocessing_fn`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c6d892-9e2f-4746-9b6b-8846bda63ae3",
   "metadata": {},
   "source": [
    "As you'll see, we need to point the Transform component to a .py module that defines the preprocessing steps. We construct such a module below by saving a code cell to a file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72717c85-c191-429d-a477-954366d10476",
   "metadata": {},
   "outputs": [],
   "source": [
    "pets_transform_file = 'pets_transforms.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71eff40-ec79-4df3-939b-ea8dbaeb1919",
   "metadata": {},
   "outputs": [],
   "source": [
    "#?%%writefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c1709a-0a1e-4741-815e-801a2925875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {pets_transform_file}\n",
    "\n",
    "from typing import Union\n",
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "\n",
    "LABEL_KEY = \"AdoptionSpeed\"\n",
    "\n",
    "ONE_HOT_FEATURES = {\n",
    "    'Type': 2,\n",
    "    'Breed1': 166,\n",
    "    'Gender': 2,\n",
    "    'Color1': 7,\n",
    "    'Color2': 7,\n",
    "    'MaturitySize': 2,\n",
    "    'FurLength': 3,\n",
    "    'Vaccinated': 3,\n",
    "    'Sterilized': 3,\n",
    "    'Health': 3\n",
    "    \n",
    "}\n",
    "\n",
    "NUMERICAL_FEATURES = [\n",
    "    'Age',\n",
    "    'Fee',\n",
    "    'PhotoAmt' \n",
    "]\n",
    "\n",
    "TEXT_FEATURES = {'Description': None}\n",
    "\n",
    "\n",
    "def _transformed_name(key:str) -> str:\n",
    "    return key + \"_xf\"\n",
    "\n",
    "\n",
    "\n",
    "def _convert_num_to_one_hot(label_tensor: tf.Tensor, num_labels: int = 2) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Convert a label (0 or 1) into a one-hot vector\n",
    "    Args:\n",
    "        int: label_tensor (0 or 1)\n",
    "    Returns\n",
    "        label tensor\n",
    "    \"\"\"\n",
    "    one_hot_tensor = tf.one_hot(label_tensor, num_labels)\n",
    "    return tf.reshape(one_hot_tensor, [-1, num_labels])\n",
    "\n",
    "def _fill_in_missing(x: Union[tf.Tensor, tf.SparseTensor]) -> tf.Tensor:\n",
    "    \"\"\"Replace missing values in a SparseTensor.\n",
    "    Fills in missing values of `x` with '' or 0, and converts to a\n",
    "    dense tensor.\n",
    "    Args:\n",
    "      x: A `SparseTensor` of rank 2.  Its dense shape should have\n",
    "        size at most 1 in the second dimension.\n",
    "    Returns:\n",
    "      A rank 1 tensor where missing values of `x` have been filled in.\n",
    "    \"\"\"\n",
    "    if isinstance(x, tf.sparse.SparseTensor):\n",
    "        default_value = \"\" if x.dtype == tf.string else 0\n",
    "        x = tf.sparse.to_dense(\n",
    "            tf.SparseTensor(x.indices, x.values, [x.dense_shape[0], 1]),\n",
    "            default_value,\n",
    "        )\n",
    "    return tf.squeeze(x, axis=1)\n",
    "\n",
    "\n",
    "def preprocessing_fn(inputs: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"tf.transform's callback function for preprocessing inputs.\n",
    "    Args:\n",
    "        inputs: map from feature keys to raw not-yet-transformed features.\n",
    "    Returns:\n",
    "        Map from string feature key to transformed feature operations.\n",
    "    \"\"\"\n",
    "    \n",
    "    outputs = {}\n",
    "\n",
    "    for key in ONE_HOT_FEATURES:\n",
    "        dim = ONE_HOT_FEATURES[key]\n",
    "        int_value = tft.compute_and_apply_vocabulary(\n",
    "            _fill_in_missing(inputs[key]), top_k=dim+1\n",
    "        )\n",
    "        outputs[_transformed_name(key)] = _convert_num_to_one_hot(\n",
    "            int_value, num_labels=dim+1\n",
    "        )\n",
    "\n",
    "    for key in NUMERICAL_FEATURES:\n",
    "        # Scale these features to the z-score.\n",
    "        outputs[_transformed_name(key)] = tft.scale_to_z_score(inputs[key])\n",
    "            \n",
    "    for key in TEXT_FEATURES.keys():\n",
    "        outputs[_transformed_name(key)] = _fill_in_missing(inputs[key])\n",
    "\n",
    "        \n",
    "    outputs[_transformed_name(LABEL_KEY)] = _fill_in_missing(inputs[LABEL_KEY])\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a15cbc6-a162-488e-b136-429f481ea625",
   "metadata": {},
   "source": [
    "## Create and run a Transfom component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b71f72a-b9bf-499d-8cd5-3b299a5fdc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a2b361-db17-4d91-9721-db76598a05a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Transform(\n",
    "    examples=example_gen.outputs['examples'],\n",
    "    schema=schema_gen.outputs['schema'],\n",
    "    module_file=os.path.abspath(pets_transform_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e441d200-ad16-4ecf-a35a-bda9cf55a1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.run(transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40f3801-f93e-4902-bb05-2ad8ddd9e752",
   "metadata": {},
   "source": [
    "### Inspect some transformed examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ca194c-f7c0-4022-b6c8-3aff4e36cc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_uri = transform.outputs['transformed_examples'].get()[0].uri + '/Split-train'\n",
    "train_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a30b390-3f0f-43bd-97ae-fa5f35ecbd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(train_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a6872b-5663-4538-a417-9ff4cd9ddf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_dataset = tf.data.TFRecordDataset(train_uri+'/transformed_examples-00000-of-00001.gz', \n",
    "                                              compression_type=\"GZIP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0ae220-95b1-437a-a1e7-de76735b651a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beccfb34-78b9-4adc-ab3c-9e11145bac55",
   "metadata": {},
   "source": [
    "Here is the first record records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89e18b1-1a59-4a56-80f9-f61c8f38d9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tfrecord in transformed_dataset.take(1):\n",
    "    serialized_example = tfrecord.numpy()\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(serialized_example)\n",
    "    print(example)\n",
    "    print(\"#\"*40)\n",
    "    print(\"#\"*40)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe2c47d-e4f6-452b-92b8-72a7a5f9da0d",
   "metadata": {},
   "source": [
    "### The transform graph artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03f5bf7-29a4-44e2-a7e8-d6c8bd799ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_graph_uri = transform.outputs['transform_graph'].get()[0].uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504a72c6-0168-44e5-ac3e-d00cb8468694",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_graph_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec03b6f5-10ef-405e-9713-d714d54dfe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(transform_graph_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060504f0-2c98-4f51-a888-dc4b0f5d533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(transform_graph_uri + '/metadata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391271dc-ada2-4b9c-981a-d735d2a4d923",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(transform_graph_uri + '/transformed_metadata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4289fa-baf9-46e4-b45d-db12bae1ff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(transform_graph_uri + '/transform_fn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1986bde5-8bdb-4381-9ad4-3160298e9018",
   "metadata": {},
   "source": [
    "# What have we done so far?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7f2d46-dd58-4d39-bc2e-2c991591b5bd",
   "metadata": {},
   "source": [
    "Here's our current pipeline:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2fd9d5-0273-4dd6-8eb1-214175fcf33a",
   "metadata": {},
   "source": [
    "<img width=60% src=\"assets/pipeline_3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e4e11a-686a-4e30-aafd-1f4e9a590353",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# What's next?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf04617e-e3bb-4063-925f-fd5110fb1967",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We now have a pipeline that ingests data, computes statistics, generates a data schema, applies the schema to validate examples, and preprocesses the examples. Next, we'll look at how to do the actual **training of machine learning models**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d5010e-62fe-4e88-abcf-44cc5562ef5f",
   "metadata": {},
   "source": [
    "The training will be done by a TFX **Trainer** component, which consumes the transformed examples from the `Transform` component, and the data schema. \n",
    "\n",
    "We'll end up with the following pipeline:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ffde56-b4fb-4803-bbdd-46da7e0afad4",
   "metadata": {},
   "source": [
    "<img width=100% src=\"assets/pipeline_4.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfx]",
   "language": "python",
   "name": "conda-env-tfx-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
