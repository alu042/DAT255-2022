{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1002b202-2e84-4941-b220-7242d59cc16c",
   "metadata": {},
   "source": [
    "Alexander S. Lundervold, 03.04.22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb3c5e9-edf3-4eee-884b-5f66324ef0d8",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474f9a3c-f75c-4131-8988-446a91999f01",
   "metadata": {},
   "source": [
    "After ingesting some data, the next step is to **validate** it. We don't want to pass data on to the next step in our ML pipeline unless it passes some checks. Among other things, we need to make sure that there are no _anomalies_, i.e., deviations from what's expected, that the data's statistics are similar to the one we expect, and that it conforms to our data schema. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e893f4a-b0f8-40b6-bec1-0d011cfe024e",
   "metadata": {},
   "source": [
    "In TensorFlow Extended, we can add various validation components from the [TensorFlow Data Validation (TFDV) library](https://www.tensorflow.org/tfx/data_validation/get_started)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5468e5-0132-4120-b195-0f0d5033a3fe",
   "metadata": {},
   "source": [
    "We'll build on the pipeline we constructed in `1.0-data_ingestion.ipynb`:\n",
    "\n",
    "<img width=60% src=\"assets/pipeline_1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d62dd1-eb47-4272-9d7d-76af6d611f70",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2037fd29-01b9-4da6-84ec-bebefcab9717",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1a743b-4763-4bf4-bac6-bccea6ffa4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether we're running on Colab\n",
    "try:\n",
    "    import colab\n",
    "    colab=True\n",
    "except:\n",
    "    colab=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ed77a8-89fe-4ecd-b8e1-d8c9aeb71fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab:\n",
    "    !pip install -U tfx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8192a09-2fc1-4240-9d00-63a57e578a46",
   "metadata": {},
   "source": [
    "> If on Colab, restart the runtime after running the above cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5b80eb-cc3d-406a-a963-b9ff9dc58c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be6892b-d107-4174-89b2-cfade1231473",
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('./gdrive')\n",
    "    DATA = Path('./gdrive/MyDrive/ColabData/petfinder-mini/csv')\n",
    "else:\n",
    "    NB_DIR = Path.cwd()\n",
    "    DATA = NB_DIR/'..'/'data'/'petfinder-mini'/'csv'\n",
    "    \n",
    "SPLIT_DATA = DATA/'..'/'split_csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd86dbba-ee10-4bb5-b8c4-2eb7e195cbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d4fd8a-b986-49a5-acd5-8aac3d3f56a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = InteractiveContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30ee8fe-934c-4823-ab5c-37d22be7a3ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Ingest data and generate statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97750191-3de3-44ce-a5bf-a19415e95a2d",
   "metadata": {},
   "source": [
    "The below is copied from `1.0-data_ingestion.ipynb`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e6f8f7-fe76-434c-a0ea-48fa30cdf652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.components import CsvExampleGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d869b32-2d56-4b97-b6a9-946312689c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.proto import example_gen_pb2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958f24a8-73e2-4999-b605-d86ff77f5dbf",
   "metadata": {},
   "source": [
    "We'll use a 8:2 split of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bdd315-076f-47e4-958e-2fffad455688",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_config = example_gen_pb2.Output(\n",
    "                split_config=example_gen_pb2.SplitConfig(splits=[\n",
    "                    example_gen_pb2.SplitConfig.Split(name='test', hash_buckets=1)\n",
    "                        ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb689cd-fbd9-49b0-980e-7d5534489524",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_gen = CsvExampleGen(input_base=str(DATA)+'/', \n",
    "                            input_config=None, output_config=output_config, \n",
    "                            range_config=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab90d171-dccd-4818-b980-9a9400f30b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.components import StatisticsGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960e705d-5df9-4f7d-944c-d92d02eb94f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "statistics_gen = StatisticsGen(\n",
    "        examples=example_gen.outputs['examples'],\n",
    "        schema=None,\n",
    "        stats_options=None,\n",
    "        exclude_splits=None\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf32924-6e0b-4e11-ae52-7dcc7b906fd6",
   "metadata": {},
   "source": [
    "# Execute the components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a22894-6354-46b2-a7ad-16236d8c49a0",
   "metadata": {},
   "source": [
    "As we're playing the role as orchestrator, we need to run the components in some order. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5fe8fc-c9d1-47c2-b48e-36089343f03c",
   "metadata": {},
   "source": [
    "First, we run our `ExampleGen`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787a2653-9a66-4d23-a472-6809d13281fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.run(example_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910051e1-00a3-4b21-a055-eaafbafe4b58",
   "metadata": {},
   "source": [
    "Then our `StatisticsGen`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2598b0-650e-42f2-8c00-14a9642ff528",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.run(statistics_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1146674-09ab-427c-8c07-15ed7874b023",
   "metadata": {},
   "source": [
    "This gives us some statistics that we can visualize: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b512e1c7-a6ae-411b-8b44-6ef9cc428b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.show(statistics_gen.outputs['statistics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d151d5b5-dbda-4f3d-9076-c4ce54c57e35",
   "metadata": {},
   "source": [
    "Nothing new yet. The above simply reproduced the pipeline we constructed in `1.0-data_ingestion.ipynb`\n",
    "\n",
    "<img width=30% src=\"assets/pipeline_1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d5f805-01da-4152-8d8e-8e00fae860ac",
   "metadata": {},
   "source": [
    "What can we do with the statistics we've computed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd32fdb8-c226-4cd1-909c-55b03ba4fc46",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generate a data schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f3482f-2f0e-4cb7-8059-ceee6f68aaeb",
   "metadata": {},
   "source": [
    "A data schema contains all the features in the dataset and their corresponding data types. It can also define the expected bounds and other properties of the features. Having a schema is important for reading, interpreting, applying the correct feature transformations, and, importantly, detect anomalies in the input data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17200ef5-32a2-4b86-883e-6e3a0f43aa88",
   "metadata": {},
   "source": [
    "The `SchemaGen` component can infer a data schema automatically from the generated statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6a22b8-8bf0-4402-ac78-25eea815f1aa",
   "metadata": {},
   "source": [
    "## Automatically generated schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc375d4c-6a46-476e-ace4-d80ec9e2998e",
   "metadata": {},
   "source": [
    " Our `StatisticsGen` component can be used as input, and a data schema proto is produced: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69834558-9da1-4aa3-ac29-aca40af7515d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "schema_gen = tfx.components.SchemaGen(\n",
    "    statistics=statistics_gen.outputs['statistics'],\n",
    "    infer_feature_shape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09179ae8-00c9-4c25-9a60-7cf7ce07815e",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.run(schema_gen, enable_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9801b325-6234-4c3f-bb74-29d23122dd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.show(schema_gen.outputs['schema'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da19e4e-f333-407d-a4c2-8be33750543a",
   "metadata": {},
   "source": [
    "Note that the automatically generated features isn't necessarily correct, but rather a starting point to define a data schema. It's important that the schema is correct (you'll see why when we use the schema below), so manual modifications are typically needed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db6675c-dadf-4df3-a7f4-87660dbdb5c1",
   "metadata": {},
   "source": [
    "## Manual modifications of the data schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a995e3a-66ed-4562-942d-4d31d1587770",
   "metadata": {},
   "source": [
    "In the above schema, all the features are marked as \"Required\" because all of them were avaliable in the training data. That's not necessarily something we want, as we may expect that certain features will be missing once we put our pipeline in production. Also, we may want to restrict the range of values for some of our numerical features. \n",
    "\n",
    "For example, let's say that we know that the fur length will sometimes be missing. Then we'd like to make it optional. However, as we would want to keep training a model after it's been put into production, a natural thing to ask for is that certain features are present for at least a given percentage of the training data. For example, maybe we need to know the fur length for 90% of the training instances. \n",
    "\n",
    "Also, perhaps we want to make sure that there are no negative values entered for \"Age\", and no ages above 30 (as those would probably be mistyped). \n",
    "\n",
    "Let's edit the data schema to reflect this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd679f75-f0cf-4f77-8235-053a67567a7c",
   "metadata": {},
   "source": [
    "The schema is an artifact of our `schema_gen`. It is stored on disk as a protobuf text file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec1f430-ef05-4851-826e-ef092e1c383f",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_gen.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2619c3e6-a719-48e3-b5bc-43b2377878ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_gen.outputs['schema']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb788588-b9e5-4dd9-a175-3a245abf4aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_gen.outputs['schema'].get()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e900c6-2f4d-4d6c-8570-486a77713b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "URI = schema_gen.outputs['schema'].get()[0].uri\n",
    "URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9662827-ce74-4b8a-98ee-591619fcb6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9299c07a-aeab-4334-abd0-f4a1462420a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_uri = URI + '/schema.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183721c5-21b9-4bb7-bb7c-cad7f8ff6bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat $schema_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd52b587-7479-406d-92fc-7d20647da96e",
   "metadata": {},
   "source": [
    "Rather than updating the file manually, we can use `TensorFlow Data Validation`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebd5fbd-693f-4913-81f6-aece5791445e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_data_validation as tfdv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fef847e-6705-4b1d-a2a8-afefec4560a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = tfdv.load_schema_text(schema_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707d3155-79c9-4d07-88cf-bd31c67e2d84",
   "metadata": {},
   "source": [
    "### Updating the features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dec9e8-d6bd-47f8-ab7c-e906ae3b847f",
   "metadata": {},
   "source": [
    "**Fur length**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daccb57-785a-4d6d-9bf4-3500a738a1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fur_feature = tfdv.get_feature(schema, \"FurLength\")\n",
    "fur_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa16c255-055e-4b12-810a-53bc9c1c8381",
   "metadata": {},
   "outputs": [],
   "source": [
    "fur_feature.presence.min_fraction = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6980ee2e-51e6-4550-824b-a3d09dfb1c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fur_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55188e32-cbaf-4626-bf76-398f9525ed6b",
   "metadata": {},
   "source": [
    "**Age**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50b86c3-4d87-43c0-904c-9f6f1324334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_feature = tfdv.get_feature(schema, \"Age\")\n",
    "age_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41103be2-13dd-4bc1-ac68-d0f991066329",
   "metadata": {},
   "source": [
    "Update the domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e649b21-b1ff-46fb-ae69-fbf29c344d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_metadata.proto.v0 import schema_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2af57c-943b-4c22-8475-230a1b73935a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdv.set_domain(schema, \"Age\", schema_pb2.IntDomain(min=0, max=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a9658f-0e8b-47b0-a00f-71bc4cd15880",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d645401-01a6-47e4-8d19-4001c9fc444a",
   "metadata": {},
   "source": [
    "### Our updated schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1882b9-a87f-45b4-8169-cb889190788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdv.display_schema(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc04ff4-d881-42c6-95e4-1c75d386135b",
   "metadata": {},
   "source": [
    "### Saving the updated data schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21858668-9cd2-413a-8595-5b60e7d7070d",
   "metadata": {},
   "source": [
    "Now we can write the updated schema to disk for later use. We replace the artifact generated by the above `SchemaGen` with our modified version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae32788b-b66c-4b31-a660-a09077fba09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdv.write_schema_text(schema, schema_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96466c6b-2fcb-40a6-bb03-b2ee192bd77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.show(schema_gen.outputs['schema'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4cecdf-33a0-4fd3-96a4-64e377df540f",
   "metadata": {},
   "source": [
    "# Identify anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea34ff20-4c45-45f1-a7bb-d4fbdc07855f",
   "metadata": {},
   "source": [
    "Using the data schema, we can detect anomalies in our data simply by comparing a data instance to the data schema. The `ExampleGen` component can be used to achieve this. It stops the pipeline if anomalies are detected. Produces an artifact in the MetadataStore indicating that it failed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f026cf9-fe3b-4ccd-95ec-b8123eb0a7ed",
   "metadata": {},
   "source": [
    "We use the schema we edited above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5a6f82-534e-4c55-9dc7-3f6ebaa47e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_validator = tfx.components.ExampleValidator(\n",
    "        statistics=statistics_gen.outputs['statistics'],\n",
    "        schema=schema_gen.outputs['schema'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dff06be-a4c9-4445-b5a6-73b4ef7986b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.run(example_validator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b28631-a79f-46e3-812d-955352431d89",
   "metadata": {},
   "source": [
    "It produces artifacts that list whether or not each instance failed or not. Let's have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62438db5-4b75-4e86-ac7d-f46849265f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.show(example_validator.outputs['anomalies'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4e0c5a-29d1-43cd-88e2-371ac4952c31",
   "metadata": {},
   "source": [
    "Here's how it would look if there were more anomalies. First we need more instances that doesn't conform to the data schema:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a9bab8-61d0-407d-beec-09e14420b982",
   "metadata": {},
   "source": [
    "## Anomalous instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf9e324-bac8-44a4-97a8-dda97c3f4fc2",
   "metadata": {},
   "source": [
    "Let's see what happens if we feed in instances that doesn't conform to the data schema. Back in `0.0-prepare_data.ipynb`, we made some instances that had values for features that are in different ways out of the feature domains in the above schema (f.ex. a value \"Bird\" for the feature \"Type\"). \n",
    "\n",
    "We can load these and run them through the `example_gen`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692b5e60-f189-484d-825b-6b888f1b76c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_config = example_gen_pb2.Input(\n",
    "    splits=[\n",
    "        example_gen_pb2.Input.Split(name='test', pattern='span3*')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85c7c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_config = example_gen_pb2.Output(\n",
    "                split_config=example_gen_pb2.SplitConfig(splits=[\n",
    "                    example_gen_pb2.SplitConfig.Split(name='test', hash_buckets=1)\n",
    "                        ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88c0ced-2d1b-40e0-a292-fde1df254265",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_gen_anomalous = CsvExampleGen(input_base=str(SPLIT_DATA)+'/',\n",
    "                                 input_config=input_config, output_config=output_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6ede8c-6f99-46c4-9e92-3802eff91a4c",
   "metadata": {},
   "source": [
    "We can check the data in `test` for anomalies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d807420-b18a-4b87-a9f8-fc6a31b79e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_gen_anomalous = StatisticsGen(\n",
    "        examples=example_gen_anomalous.outputs['examples'],\n",
    "        schema=None,\n",
    "        stats_options=None,\n",
    "        exclude_splits=None\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa536b97-64e9-4866-8b6a-96055c0f3984",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_validator_anomalous = tfx.components.ExampleValidator(\n",
    "        statistics=statistics_gen_anomalous.outputs['statistics'],\n",
    "        schema=schema_gen.outputs['schema'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0830d8-3f45-4bd7-bf52-9eef3a0ac4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.run(example_gen_anomalous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84a76e6-9091-48f5-b59f-5612b01b5a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.run(statistics_gen_anomalous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d10f3b7-e7a5-4d8b-8cdf-297552548beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.run(example_validator_anomalous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b16db12-f878-48b0-b88d-13702e8a8bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.show(example_validator_anomalous.outputs['anomalies'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f35735-7eda-42dc-b343-1198c8e2e2f7",
   "metadata": {},
   "source": [
    "Once we've added further components to our ML pipleine, the anomalies in the above dataset would make the `ExampleValidatior` component stop the downstream components from running, enabling us to catch the problem without doing any additional time-consuming data preprocessing or model training (and, importantly, produce output predictions on data our ML pipeline isn't constructed to handle)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6e5d4a-4b14-4379-a587-52cfd1f039af",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caab6f4-a054-4fb2-91b3-598af2c20239",
   "metadata": {},
   "source": [
    "<img width=60% src=\"assets/pipeline_2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e225dece-9fd6-420c-ad47-4955478be1c2",
   "metadata": {},
   "source": [
    "# Other forms of data validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01e38f1-dbb1-40a2-b3c4-17528b5ede3b",
   "metadata": {},
   "source": [
    "## Comparing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e52557-121a-4221-b7dd-1564415c4e6d",
   "metadata": {},
   "source": [
    "In practice one often need to compare datasets. Do their statistics differ? How similar is my validation or test data to the training data? Is my new dataset conforming to the data schema? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1b703a-b911-4f0a-89fe-40403562b37a",
   "metadata": {},
   "source": [
    "We can do this by directly using the TensorFlow Data Validation library on which the data validation components of TFX is based."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298889f2-20d2-4a06-882d-9fb0b9588e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_data_validation as tfdv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291e8df7-bb59-4809-bd66-6002676f390a",
   "metadata": {},
   "source": [
    "We load the datasets that we want to compare from the splits we set up in notebook `0.0`. \n",
    "\n",
    "How different are the two data sets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac50fbc5-398a-4edf-ad59-9c2983b486e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "span1_stats = tfdv.generate_statistics_from_csv(data_location=str(SPLIT_DATA/'span1.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1708fc0-0029-4d56-8293-4d6e266a190b",
   "metadata": {},
   "outputs": [],
   "source": [
    "span2_stats = tfdv.generate_statistics_from_csv(data_location=str(SPLIT_DATA/'span2.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb685837-b3b0-4d7f-a10d-b876ace4bc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdv.visualize_statistics(lhs_statistics=span1_stats, rhs_statistics=span2_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6767d14b-360c-4fb0-8f5e-e3cec6b4ae2d",
   "metadata": {},
   "source": [
    "This is a great way to catch possible problems related to the training-, validation- and test-sets being different. For example, checking wether the test set is representative of the data the model is trained on. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2404eedd-e01f-45bb-9568-4aaab4adc170",
   "metadata": {},
   "source": [
    "## More data validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfccda05-2903-43c2-802b-50186d65d34d",
   "metadata": {},
   "source": [
    "Have a look at the TensorFlow Data Validation for additional data validation functionality (f.ex. detecting data drift, bias, comparing slices of the datasets, etc): https://www.tensorflow.org/tfx/guide/tfdv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297f67c5-a77a-477f-bff4-d7aea7bd3dc2",
   "metadata": {},
   "source": [
    "# What's next?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18233a29-9a7a-40a5-983b-7f38c586776e",
   "metadata": {},
   "source": [
    "We now have a pipeline that ingests data, computes statistics, generates a data schema, and applies the schema to validate examples. Next, we'll look at how to do **data preprocessing**: encoding features, preprocessing features, feature engineering, and more. All the things we need to transform our raw data into a form suitable for our machine learning models. \n",
    "\n",
    "In TensorFlow Extended, this is done using the [TensorFlow Transform](https://www.tensorflow.org/tfx/transform/get_started), built on [Apache Beam](https://beam.apache.org/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfx]",
   "language": "python",
   "name": "conda-env-tfx-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
